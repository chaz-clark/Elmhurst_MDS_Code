---
title: "Regression"
output: html_notebook
name: Chaz Clark
---
```{r}
#7.1 Loading the Plums Data
##Make sure to set directory to location of downloaded file or specify path in load call
#load("C://Users/e0005267/OneDrive - Elmhurst College/MDS/MDS 556 19SP/psub.RData")
dtrain <- subset(psub, ORIGRANDGROUP >= 500)
dtest <- subset(psub, ORIGRANDGROUP < 500)
model <- lm(log(PINCP,base=10) ~ AGEP + SEX + COW + SCHL, data=dtrain)
dtest$predLogPINCP <- predict(model, newdata= dtest)
dtrain$predLogPINCP <- predict(model, newdata = dtrain)
head(dtest$predLogPINCP)
```

```{r}
#7.2 PLotting Log Income as a Function of Predicted Log Income
#install.packages("ggplot2")
library(ggplot2)
ggplot(data=dtest, aes(x=predLogPINCP, y=log(PINCP, base=10))) + 
  geom_point(alpha=0.2, color="black") +
  geom_smooth(aes(x=predLogPINCP,
                  y=log(PINCP, base=10)), color="black") + 
  geom_line(aes(x=log(PINCP, base=10),
                y=log(PINCP, base=10)), color="blue", linetype=2) +
  scale_x_continuous(limits=c(4,5)) +
  scale_y_continuous(limits=c(3.5,5.5))
```

```{r}
#7.3 PLotting residuals Income as a Function of Predicted Log Income
ggplot(data=dtest, aes(x=predLogPINCP,
                       y=predLogPINCP-log(PINCP,base=10))) + 
  geom_point(alpha=.2, color="black") +
  geom_smooth(aes(x=predLogPINCP,
                  y=predLogPINCP-log(PINCP,base=10)),
              color="black")
```

```{r}
#7.4 Computing R-squared
rsq <- function(y,f) {1 - sum((y-f)^2)/sum((y-mean(y))^2) }
rsq(log(dtrain$PINCP, base=10), predict(model, newdata=dtrain))
rsq(log(dtest$PINCP, base=10), predict(model, newdata=dtest))
```

```{r}
#7.5 Calculating Root Mean Squared Error
rmse<- function(y,f) {sqrt(mean( (y-f)^2 )) }
rmse(log(dtrain$PINCP, base=10), predict(model, newdata=dtrain))
rmse(log(dtest$PINCP, base=10), predict(model, newdata=dtest))
```

```{r}
#7.6 Summarizing Resifuals
summary(log(dtrain$PINCP, base=10) - predict (model, newdata=dtrain))
summary(log(dtest$PINCP, base=10) - predict (model, newdata=dtest))
```

```{r}
#7.7 Loading the CDC Data
##Make sure to set directory to location of downloaded file or specify path in load call
#load('NatalRiskData.rData')
train <- sdata[sdata$ORIGRANDGROUP<= 5, ]
test <-  sdata[sdata$ORIGRANDGROUP>5, ]
```

```{r}
#7.8 Building the model Formula
complications <- c("ULD_MECO","ULD_PRECIP","ULD_BREECH")
riskfactors <- c("URF_DIAB","URF_CHYPER","URF_PHYPER","URF_ECLAM")
y <- "atRisk"
x <- c("PWGT",
       "UPREVIS",
       "CIG_REC",
       "GESTREC3",
       "DPLURAL",
       complications,
       riskfactors)
fmla<- paste(y, paste(x, collapse="+"), sep="~")
```

```{r}
#7.9 Fitting the Logistic Regression Model
print(fmla)
model <- glm(fmla, data=train, family=binomial(link="logit"))
```

```{r}
#7.10 Applying the Logistic Regression Model
train$pred <- predict(model, newdata=train, type="response")
test$pred <- predict(model, newdata=test, type="response")
```

```{r}
#7.11 PLotting Distribution of Prediction scores grouped by known outcomes
library(ggplot2)
ggplot(train, aes(x=pred, color=atRisk, linetype=atRisk)) + geom_density()
```

```{r}
#7.12 Exploring Modeling trade-offs
library(ROCR)
library(grid)
predObj <- prediction(train$pred, train$atRisk)
precObj <- performance(predObj, measure = 'prec')
recObj <- performance(predObj, measure='rec')

precision <- (precObj@y.values)[[1]]
prec.x <- (precObj@x.values)[[1]]
recall <- (recObj@y.values)[[1]]

rocFrame <- data.frame(threshold=prec.x, precision=precision, recall=recall)

nplot <- function(plist) {
  n <- length(plist)
  grid.newpage()
  pushViewport(viewport(layout=grid.layout(n,1)))
  vplayout= function(x,y) {viewport(layout.pos.row=x,  layout.pos.col=y)}
  for (i in 1:n) {
    print(plist[[i]], vp=vplayout(i,1))
  }
}
 
pnull<- mean(as.numeric(train$atRisk))

p1 <- ggplot(rocFrame, aes(x=threshold)) +
  geom_line(aes(y=precision/pnull)) +
  coord_cartesian(xlim = c(0,.05), ylim = c(0,10) )
  
p2 <- ggplot(rocFrame, aes(x=threshold)) +
  geom_line(aes(y=recall)) + 
  coord_cartesian(xlim = c(0,.05) )

nplot(list(p1,p2))
```

```{r}
#7.13 Evaluating our Chosen Model
ctab.test <- table(pred=test$pred>0.02, atRisk= test$atRisk)
ctab.test
precision <- ctab.test[2,2]/sum(ctab.test[2,])
precision
recall <- ctab.test[2,2]/sum(ctab.test[,2])
recall
enrich<- precision/mean(as.numeric(test$atRisk))
enrich
```

```{r}
#7.14 The Model Coefficients
coefficients(model)
```

```{r}
#7.15 The model Summary
summary(model)
```

```{r}
#7.16 Calculating Deviance Residuals
pred <- predict(model, newdata = train, type = 'response')
  llcomponents <- function(y, py) {
  y*log(py) + (1-y)*log(1-py)
}

edev <- sign(as.numeric(train$atRisk) - pred) *
  sqrt(-2*llcomponents(as.numeric(train$atRisk), pred))

summary(edev)
```

```{r}
#7.17 Computing Deviance
loglikelihood <- function(y,py) {
  sum(y * log(py) + (1-y)*log(1-py))
}

pnull<- mean(as.numeric(train$atRisk))

null.dev<- -2*loglikelihood(as.numeric(train$atRisk), pnull)
pnull

null.dev
model$null.deviance

pred<- predict(model, newdata=train, type="response")
resid.dev<- -2*loglikelihood(as.numeric(train$atRisk), pred)
resid.dev

model$deviance

testy<- as.numeric(test$atRisk)
testpred<- predict(model, newdata=test, type = "response")

pnull.test<- mean(testy)

null.dev.test<- -2*loglikelihood(testy, pnull.test)

resid.dev.test<- -2*loglikelihood(testy, testpred)

pnull.test
null.dev.test
resid.dev.test
```

```{r}
#7.18 Calculating the Significance of the observed fit
df.null <- dim(train)[[1]] -1
df.model <- dim(train)[[1]] - length(model$coefficients)

df.null
df.model

delDev<- null.dev - resid.dev
deldf<- df.null - df.model
p<- pchisq(delDev, deldf, lower.tail = F)

delDev
deldf
p
```

```{r}
#7.19 Calculating the Pseudo R-Squared
pr2<- 1-(resid.dev/null.dev)

print(pr2)

pr2.test<- 1-(resid.dev.test/null.dev.test)
print(pr2.test)
```

```{r}
#7.20 Calculating the Akaike Information Criterion
aic <- 2*(length(model$coefficients) -
            loglikelihood(as.numeric(train$atRisk), pred))
aic
```

